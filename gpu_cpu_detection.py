# -*- coding: utf-8 -*-
"""GPU/CPU_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pfRKAXNPxF_ZZw43wK8y6HQNOqCE8ll5
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # Core CLI + utilities
!pip install -q isic-cli scikit-learn tqdm cupy-cuda12x
#

!pip install -q torch torchvision torchaudio
!pip install cupy-cuda12x

#@title Download ISIC dataset (benign vs malignant)

import os

# Root dataset directory
DATASET_DIR = "dataset"
os.makedirs(DATASET_DIR, exist_ok=True)

# Create class subdirectories
for cls in ["benign", "malignant"]:
    os.makedirs(os.path.join(DATASET_DIR, cls), exist_ok=True)

# Download malignant
!isic image download --limit 5000 --search 'diagnosis_1:"Malignant"' dataset/malignant

# Download benign
!isic image download --limit 5000 --search 'diagnosis_1:"Benign"' dataset/benign

#Split the dataset into train / val / test

import os
import random
import shutil

def split_dataset(base_dir, val_ratio=0.15, test_ratio=0.15, seed=42):
    """
    Split each class subfolder (benign/malignant) into:
    base_dir/train/<cls>, base_dir/val/<cls>, base_dir/test/<cls>
    """
    random.seed(seed)
    categories = ['benign', 'malignant']
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp')

    for category in categories:
        category_path = os.path.join(base_dir, category)
        train_path = os.path.join(base_dir, 'train', category)
        val_path = os.path.join(base_dir, 'val', category)
        test_path = os.path.join(base_dir, 'test', category)

        os.makedirs(train_path, exist_ok=True)
        os.makedirs(val_path, exist_ok=True)
        os.makedirs(test_path, exist_ok=True)

        # Filter to only include image files
        all_files = [
            f for f in os.listdir(category_path)
            if os.path.isfile(os.path.join(category_path, f))
            and f.lower().endswith(image_extensions)
        ]

        random.shuffle(all_files)

        total = len(all_files)
        val_count = int(total * val_ratio)
        test_count = int(total * test_ratio)
        train_count = total - val_count - test_count

        val_files = all_files[:val_count]
        test_files = all_files[val_count:val_count + test_count]
        train_files = all_files[val_count + test_count:]

        for file_name in val_files:
            shutil.move(os.path.join(category_path, file_name),
                        os.path.join(val_path, file_name))

        for file_name in test_files:
            shutil.move(os.path.join(category_path, file_name),
                        os.path.join(test_path, file_name))

        for file_name in train_files:
            shutil.move(os.path.join(category_path, file_name),
                        os.path.join(train_path, file_name))

        print(f"[{category}] -> Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}")

# Usage
base_dir = 'dataset'
split_dataset(base_dir)

#Shared config, model and evaluation utilities

import os
import time
import random
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from sklearn.metrics import classification_report

IMAGE_SIZE = 128
BATCH_SIZE = 32
EPOCHS = 5
CLASSES = ['benign', 'malignant']
SEED = 42

def set_seed(seed=SEED):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed()

class MoleCNN(nn.Module):
    def __init__(self):
        super(MoleCNN, self).__init__()
        self.net = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64 * (IMAGE_SIZE // 4) * (IMAGE_SIZE // 4), 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        return self.net(x)

def evaluate(model, loader, device, split_name="Val"):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(device)
            labels = labels.to(device).float()
            outputs = model(imgs).squeeze()
            probs = torch.sigmoid(outputs)
            preds = (probs > 0.5).int().cpu().tolist()
            all_preds.extend(preds)
            all_labels.extend(labels.int().cpu().tolist())

    print(f"\n=== {split_name} classification report ===")
    print(classification_report(all_labels, all_preds,
                                target_names=CLASSES, digits=4))

#@title Parallel implementation (GPU preprocessing with CuPy + custom CUDA kernel)

import cupy as cp
from torchvision import transforms
from PIL import Image

# Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device for parallel implementation: {device}")

# CUDA kernel: normalize RGB image using shared memory tiling
cuda_kernel = cp.RawKernel(r'''
extern "C" __global__
void normalize_rgb_tile(const unsigned char* __restrict__ img_in,
                        float* __restrict__ img_out,
                        int width, int height, int tile_size,
                        const float* __restrict__ means,
                        const float* __restrict__ stds) {

    extern __shared__ unsigned char tile[];  // size: 3 * tile_size * tile_size

    int tx = threadIdx.x;
    int ty = threadIdx.y;
    int ch = blockIdx.z;  // channel index: 0,1,2

    int x = blockIdx.x * tile_size + tx;
    int y = blockIdx.y * tile_size + ty;

    int img_idx  = ch * width * height + y * width + x;
    int tile_idx = ch * tile_size * tile_size + ty * tile_size + tx;

    // Load from global to shared (in-bounds only)
    if (x < width && y < height) {
        tile[tile_idx] = img_in[img_idx];
    }
    __syncthreads();  // all threads in block must reach this

    // Normalize and write back (only for in-bounds pixels)
    if (x < width && y < height) {
        float val = float(tile[tile_idx]) / 255.0f;
        val = (val - means[ch]) / stds[ch];
        img_out[img_idx] = val;
    }
}
''', 'normalize_rgb_tile')

def apply_cuda_rgb_preprocessing(image_tensor):
    """
    image_tensor: PyTorch CPU tensor, shape (3, H, W), values in [0,1].
    Returns: PyTorch CPU tensor, normalized per channel (ImageNet stats).
    Note: This function does CPU -> GPU -> CPU for educational purposes.
    """
    img_np = (image_tensor.numpy() * 255.0).astype(np.uint8)
    c, h, w = img_np.shape
    img_flat = img_np.reshape(-1)

    # Move to GPU
    img_cp_in = cp.asarray(img_flat)
    img_cp_out = cp.zeros((c * h * w,), dtype=cp.float32)

    # ImageNet RGB normalization values
    channel_means = cp.asarray([0.485, 0.456, 0.406], dtype=cp.float32)
    channel_stds  = cp.asarray([0.229, 0.224, 0.225], dtype=cp.float32)

    tile_size = 16
    block = (tile_size, tile_size)
    grid = ((w + tile_size - 1) // tile_size,
            (h + tile_size - 1) // tile_size,
            c)

    # Shared memory size in bytes (unsigned char = 1 byte)
    shared_mem = 3 * tile_size * tile_size

    cuda_kernel(grid, block,
                (img_cp_in, img_cp_out,
                 w, h, tile_size,
                 channel_means, channel_stds),
                shared_mem=shared_mem)

    result = cp.asnumpy(img_cp_out).reshape(c, h, w)
    return torch.tensor(result, dtype=torch.float32)

class CustomMoleDataset(Dataset):
    def __init__(self, root_dir):
        self.samples = []
        self.classes = CLASSES
        self.root_dir = root_dir
        for label, cls in enumerate(self.classes):
            cls_dir = os.path.join(root_dir, cls)
            if not os.path.exists(cls_dir):
                continue
            for fname in os.listdir(cls_dir):
                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):
                    self.samples.append((os.path.join(cls_dir, fname), label))

        self.to_tensor = transforms.ToTensor()

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))
        img_tensor = self.to_tensor(img)  # (3, H, W), float in [0,1]
        img_tensor = apply_cuda_rgb_preprocessing(img_tensor)
        return img_tensor, label

    def __len__(self):
        return len(self.samples)

if __name__ == "__main__":
    # Datasets
    train_dataset = CustomMoleDataset('dataset/train')
    val_dataset   = CustomMoleDataset('dataset/val')
    test_dataset  = CustomMoleDataset('dataset/test')

    # DataLoaders
    pin_mem = (device.type == "cuda")
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,
                              shuffle=True, num_workers=0,
                              pin_memory=pin_mem)
    val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE,
                              shuffle=False, num_workers=0,
                              pin_memory=pin_mem)
    test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE,
                              shuffle=False, num_workers=0,
                              pin_memory=pin_mem)

    # Model, loss, optimizer
    model = MoleCNN().to(device)
    criterion = nn.BCEWithLogitsLoss(
        pos_weight=torch.tensor([2.0], device=device)  # handle imbalance
    )
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    start_time = time.time()
    print("Started training on GPU with custom normalization kernel...\n")

    for epoch in range(EPOCHS):
        model.train()
        epoch_loss = 0.0

        for imgs, labels in train_loader:
            imgs = imgs.to(device)
            labels = labels.to(device).float()

            outputs = model(imgs).squeeze()
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item() * imgs.size(0)

        avg_loss = epoch_loss / len(train_dataset)
        print(f"\n[GPU] Epoch {epoch + 1}/{EPOCHS} - Avg Train Loss: {avg_loss:.6f}")

        # Validation metrics
        evaluate(model, val_loader, device, split_name="GPU Val")

    # Final test metrics
    evaluate(model, test_loader, device, split_name="GPU Test")

    torch.save(model.state_dict(), 'parallel.pth')
    print("\nModel saved as 'parallel.pth'")

    end_time = time.time()
    print(f"\n⏱ Total GPU pipeline time (train + val): {end_time - start_time:.2f} seconds")

#@title Sequential implementation (CPU baseline with manual normalization)

from torchvision import transforms
from PIL import Image
from tqdm import tqdm

device_cpu = torch.device("cpu")
print(f"Using device for sequential implementation: {device_cpu}")

def cpu_normalize_tensor(tensor):
    """
    Manual per-pixel normalization on CPU using ImageNet means/stds.
    tensor: shape (3, H, W), values in [0,1].
    """
    c, h, w = tensor.shape
    means = [0.485, 0.456, 0.406]
    stds  = [0.229, 0.224, 0.225]
    normalized = torch.zeros_like(tensor)
    for ch in range(c):
        for y in range(h):
            for x in range(w):
                normalized[ch, y, x] = (tensor[ch, y, x] - means[ch]) / stds[ch]
    return normalized

# Resize and convert to tensor (no normalization)
to_tensor_cpu = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor()
])

def preprocess_and_save_manual(raw_dir, output_dir):
    """
    raw_dir: dataset/train or dataset/val or dataset/test
    output_dir: preprocessed_manual/train etc.
    Saves normalized tensors (.pt) per image.
    """
    os.makedirs(output_dir, exist_ok=True)
    for cls in CLASSES:
        input_cls_dir = os.path.join(raw_dir, cls)
        output_cls_dir = os.path.join(output_dir, cls)
        if not os.path.exists(input_cls_dir):
            continue
        os.makedirs(output_cls_dir, exist_ok=True)

        files = [f for f in os.listdir(input_cls_dir)
                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

        for fname in tqdm(files, desc=f"Processing {cls} in {raw_dir}"):
            path = os.path.join(input_cls_dir, fname)
            img = Image.open(path).convert('RGB')
            tensor = to_tensor_cpu(img)   # (3, H, W), [0,1]
            norm_tensor = cpu_normalize_tensor(tensor)
            torch.save(norm_tensor, os.path.join(output_cls_dir, fname + ".pt"))

class PreprocessedMoleDataset(Dataset):
    def __init__(self, root_dir):
        self.samples = []
        self.classes = CLASSES
        for label, cls in enumerate(self.classes):
            cls_dir = os.path.join(root_dir, cls)
            if not os.path.exists(cls_dir):
                continue
            for fname in os.listdir(cls_dir):
                if fname.endswith('.pt'):
                    self.samples.append((os.path.join(cls_dir, fname), label))

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        tensor = torch.load(path)  # already normalized
        return tensor, label

    def __len__(self):
        return len(self.samples)

if __name__ == "__main__":
    start_time = time.time()
    print("\nStarting CPU preprocessing...\n")

    # Preprocess train, val, test
    preprocess_and_save_manual('dataset/train', 'preprocessed_manual/train')
    preprocess_and_save_manual('dataset/val',   'preprocessed_manual/val')
    preprocess_and_save_manual('dataset/test',  'preprocessed_manual/test')

    # Datasets
    train_dataset_cpu = PreprocessedMoleDataset('preprocessed_manual/train')
    val_dataset_cpu   = PreprocessedMoleDataset('preprocessed_manual/val')
    test_dataset_cpu  = PreprocessedMoleDataset('preprocessed_manual/test')

    # DataLoaders (can use a few workers here)
    train_loader_cpu = DataLoader(train_dataset_cpu, batch_size=BATCH_SIZE,
                                  shuffle=True, num_workers=4)
    val_loader_cpu   = DataLoader(val_dataset_cpu, batch_size=BATCH_SIZE,
                                  shuffle=False, num_workers=4)
    test_loader_cpu  = DataLoader(test_dataset_cpu, batch_size=BATCH_SIZE,
                                  shuffle=False, num_workers=4)

    model_cpu = MoleCNN().to(device_cpu)
    criterion_cpu = nn.BCEWithLogitsLoss(
        pos_weight=torch.tensor([2.0], device=device_cpu)
    )
    optimizer_cpu = torch.optim.Adam(model_cpu.parameters(), lr=1e-3)

    print("\nTraining started on CPU using manually preprocessed data...\n")

    for epoch in range(EPOCHS):
        model_cpu.train()
        epoch_loss = 0.0

        for imgs, labels in tqdm(train_loader_cpu,
                                 desc=f"Epoch {epoch + 1}/{EPOCHS}"):
            imgs = imgs.to(device_cpu)
            labels = labels.to(device_cpu).float()

            outputs = model_cpu(imgs).squeeze()
            loss = criterion_cpu(outputs, labels)

            optimizer_cpu.zero_grad()
            loss.backward()
            optimizer_cpu.step()

            epoch_loss += loss.item() * imgs.size(0)

        avg_loss = epoch_loss / len(train_dataset_cpu)
        print(f"\n[CPU] Epoch {epoch + 1}/{EPOCHS} - Avg Train Loss: {avg_loss:.6f}")

        # Validation metrics
        evaluate(model_cpu, val_loader_cpu, device_cpu, split_name="CPU Val")

    # Final test metrics
    evaluate(model_cpu, test_loader_cpu, device_cpu, split_name="CPU Test")

    torch.save(model_cpu.state_dict(), 'sequential.pth')
    print("\nModel saved as 'sequential.pth'")

    end_time = time.time()
    print(f"\n⏱ Total CPU pipeline time (preproc + train + val): {end_time - start_time:.2f} seconds")
